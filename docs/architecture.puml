@startuml CourseMaster_AI_Architecture

!define LIGHTORANGE #FFE4B5
!define LIGHTBLUE #ADD8E6
!define LIGHTGREEN #90EE90
!define LIGHTPINK #FFB6C1
!define LIGHTYELLOW #FFFFE0

' Title
title CourseMaster AI - System Architecture

' User Layer
actor "Student User" as user #LIGHTYELLOW

' Frontend Layer
package "Frontend Layer" #LIGHTBLUE {
  component "React Application\n(Vite + Tailwind)" as react
  component "React Router" as router
  component "Axios Client" as axios
}

' Backend API Layer
package "Backend Layer" #LIGHTGREEN {
  component "FastAPI Server\n(Port 8000)" as fastapi
  
  package "Routers" {
    component "Auth Router" as auth_router
    component "PDF Router" as pdf_router
    component "Chat Router" as chat_router
    component "Quiz Router" as quiz_router
    component "Analytics Router" as analytics_router
  }
  
  package "Services" {
    component "LangChain Service\n(Quiz Generation)" as langchain
    component "RAG Service\n(Document Retrieval)" as rag
    component "Groq Client\n(LLM Interface)" as groq_service
    component "Comprehensive Answer" as comp_answer
  }
  
  component "JWT Middleware" as jwt
  component "Logging System\n(JSON Logs)" as logging
}

' Data Layer
package "Data Storage" #LIGHTORANGE {
  database "PostgreSQL\n(Supabase)" as postgres {
    collections "users"
    collections "pdfs"
    collections "chats"
    collections "quizzes"
    collections "weaknesses"
  }
  
  database "ChromaDB\n(Vector Store)" as chroma {
    collections "embeddings"
    collections "chunks"
  }
  
  folder "File System" as files {
    file "uploads/"
    file "logs/"
  }
}

' External Services
cloud "External Services" #LIGHTPINK {
  component "Groq API\n(LLaMA 3.3 70B)" as groq_api
  component "HuggingFace\n(Sentence Transformers)" as huggingface
}

' User Interactions
user --> react : "Browse\n(localhost:5173)"

' Frontend to Backend
react --> router
router --> axios
axios --> fastapi : "REST API\n(JSON)"

' API Routing
fastapi --> auth_router
fastapi --> pdf_router
fastapi --> chat_router
fastapi --> quiz_router
fastapi --> analytics_router

fastapi --> jwt : "Token Validation"
fastapi --> logging : "Request/Response Logs"

' PDF Upload Flow
pdf_router --> rag : "Process PDF"
rag --> files : "Store File"
rag --> huggingface : "Generate Embeddings"
rag --> chroma : "Store Vectors"
pdf_router --> postgres : "Save Metadata"

' Chat Flow
chat_router --> rag : "Retrieve Chunks (20)"
rag --> chroma : "Vector Search"
chat_router --> comp_answer : "Generate Answer"
comp_answer --> groq_service
groq_service --> groq_api : "LLM Request"
chat_router --> postgres : "Save Chat History"

' Quiz Flow
quiz_router --> rag : "Get Context (30 chunks)"
quiz_router --> langchain : "Generate Quiz"
langchain --> groq_service
quiz_router --> postgres : "Save Quiz + Results"

' Analytics Flow
analytics_router --> postgres : "Query Weaknesses"

' Logging
pdf_router --> logging
chat_router --> logging
quiz_router --> logging

' Notes
note right of langchain
  LangChain Agent:
  - RetrievalQA chains
  - Structured output
  - 3 difficulty levels
  - Up to 20 MCQs
end note

note right of rag
  RAG Pipeline:
  - 512 token chunks
  - 50 token overlap
  - Cosine similarity
  - Top-k retrieval
end note

note right of chroma
  Vector Storage:
  - Per-user collections
  - Persistent storage
  - all-MiniLM-L6-v2
end note

note right of groq_api
  LLM Features:
  - Chat completions
  - Quiz generation
  - Weakness analysis
  - Max 2000 tokens
end note

@enduml
